{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d42a44f-ff96-46c7-8102-fe739752e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7601d9d-c8a9-437f-a149-3ba2266305f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe0256-b34c-45c7-ba51-db8bf9eab440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function to convert text into a usable form\n",
    "def preprocess_text(text):\n",
    "    chars = sorted(list(set(text)))  # Get all unique characters\n",
    "    char_to_idx = {ch: i for i, ch in enumerate(chars)}  # Char -> index\n",
    "    idx_to_char = {i: ch for i, ch in enumerate(chars)}  # Index -> char\n",
    "\n",
    "    return chars, char_to_idx, idx_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c73920c-a466-4bef-b26b-134cbb4cbabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text to work with\n",
    "with open('obama.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de99833b-3730-4ff0-a6bf-021a0429fe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "chars, char_to_idx, idx_to_char = preprocess_text(text)\n",
    "input_size = len(chars)  # Total unique characters in the text\n",
    "hidden_size = 128        # Size of the hidden layers\n",
    "seq_length = 100         # Length of the input sequence (can be adjusted)\n",
    "batch_size = 64          # Batch size\n",
    "learning_rate = 0.002    # Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bc8f53-1c88-4d21-8235-178cfb68f736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to a sequence of integers\n",
    "data = [char_to_idx[ch] for ch in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a9551a-0872-406b-964e-07eedbffe6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM Model\n",
    "class LSTMTextGenerator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMTextGenerator, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Initialize hidden and cell states to zeros\n",
    "        return (torch.zeros(1, batch_size, self.hidden_size),\n",
    "                torch.zeros(1, batch_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb791c-5690-4c3d-bf0b-1410f5af9816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the character indices\n",
    "def one_hot_encode(sequence, n_labels):\n",
    "    one_hot = np.zeros((len(sequence), n_labels), dtype=np.float32)\n",
    "    for i, value in enumerate(sequence):\n",
    "        one_hot[i, value] = 1.0\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeeabca-6820-4119-983d-3c61b7995983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate text\n",
    "def generate_text(model, start_str, char_to_idx, idx_to_char, length=100):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Convert the starting string to tensor\n",
    "    input_data = [char_to_idx[ch] for ch in start_str]\n",
    "    input_tensor = torch.tensor(one_hot_encode(input_data, input_size)).unsqueeze(0)\n",
    "\n",
    "    hidden = model.init_hidden(1)\n",
    "    predicted_text = start_str\n",
    "\n",
    "    for _ in range(length):\n",
    "        output, hidden = model(input_tensor, hidden)\n",
    "        output = output[:, -1, :]  # Get the last prediction\n",
    "        _, top_idx = torch.topk(output, k=1)\n",
    "        predicted_char = idx_to_char[top_idx.item()]\n",
    "        predicted_text += predicted_char\n",
    "\n",
    "        # Prepare next input\n",
    "        input_tensor = torch.tensor(one_hot_encode([top_idx.item()], input_size)).unsqueeze(0)\n",
    "\n",
    "    return predicted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c943f5-1b82-41be-b15a-b4df4bf05cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters and data preparation\n",
    "n_epochs = 100\n",
    "model = LSTMTextGenerator(input_size, hidden_size, input_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04343a61-fa98-4881-adc0-1a98665ce22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training (sliding window approach)\n",
    "def get_batches(data, seq_length, batch_size):\n",
    "    n_batches = len(data) // (seq_length * batch_size)\n",
    "    data = data[:n_batches * batch_size * seq_length]\n",
    "    data = np.array(data)\n",
    "    data = data.reshape((batch_size, -1))\n",
    "    for i in range(0, data.shape[1], seq_length):\n",
    "        x = data[:, i:i+seq_length]\n",
    "        y = np.roll(x, shift=-1, axis=1)  # Shift the input sequence to get the target\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e50404f-9a68-4948-be8e-5f5c83d162c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
