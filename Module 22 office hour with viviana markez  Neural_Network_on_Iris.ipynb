{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load libraries"
      ],
      "metadata": {
        "id": "_HQIrsWs2ePU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # install pytorch using https://pytorch.org/\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "t5Sr4kdA2dr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set the Device\n",
        "\n",
        "You should determine if a GPU is available and set your device accordingly."
      ],
      "metadata": {
        "id": "2rDp6iki3Kjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Code for MPS (Apple's Metal Performance Shaders)\n",
        "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "# print(f\"Using {device} device\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkwgOVTX3IGc",
        "outputId": "b3bb8001-2854-45e3-9b5d-6a24552ed7c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Iris dataset"
      ],
      "metadata": {
        "id": "S6Gk5hSc3Ewq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGXdz8g_1zXE"
      },
      "outputs": [],
      "source": [
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the dataset into a training set and a test set"
      ],
      "metadata": {
        "id": "1xhuKVD63Q5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "HD4n64bX3NCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert datasets to PyTorch tensors\n",
        "\n",
        "In PyTorch, the .to(device) method is used to explicitly move tensors or models to a specific device, either the CPU or a GPU. When you're training neural networks, especially deep ones, computational requirements can be high, and utilizing a GPU can significantly speed up the training process."
      ],
      "metadata": {
        "id": "Z5kwalZq3u4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.FloatTensor(X_train).to(device)\n",
        "y_train = torch.LongTensor(y_train).to(device)\n",
        "X_test = torch.FloatTensor(X_test).to(device)\n",
        "y_test = torch.LongTensor(y_test).to(device)\n"
      ],
      "metadata": {
        "id": "nKZ6ktZq3T8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the neural network structure\n",
        "\n",
        "Creating a class is a recommended way to define models in PyTorch. The class-based structure allows for organized, modular, and scalable code. You can create more straightforward models using just functions, but using classes provides greater flexibility, especially for complex architectures.\n",
        "\n",
        "### Notes:\n",
        "- 12 and 8 are somewhat arbitrary numbers. In practice, choosing the number of neurons and layers often involves experimentation.\n",
        "- `nn.Linear` denotes fully connected layers, where each neuron from the previous layer connects to every neuron in the current layer.\n",
        "- ReLU (Rectified Linear Unit) is a popular choice for hidden layers due to its simplicity and effectiveness.\n",
        "- The last layer often doesn't use an activation function because the choice of loss function in the next step (criterion) sometimes includes it.\n",
        "  - For classification tasks with multiple classes, `CrossEntropyLoss` in PyTorch combines a SoftMax activation with a cross-entropy loss."
      ],
      "metadata": {
        "id": "D1Ma89CW4SXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IrisNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IrisNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 12)    # First hidden layer with 12 neurons\n",
        "        self.fc2 = nn.Linear(12, 8)   # Second hidden layer with 8 neurons\n",
        "        self.fc3 = nn.Linear(8, 3)    # Output layer with 3 neurons (for the 3 classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))  # Apply ReLU activation function after first hidden layer\n",
        "        x = torch.relu(self.fc2(x))  # Apply ReLU activation function after second hidden layer\n",
        "        x = self.fc3(x)              # No activation here as we'll use CrossEntropyLoss\n",
        "        return x"
      ],
      "metadata": {
        "id": "kVExpgEK31F0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = IrisNet().to(device)"
      ],
      "metadata": {
        "id": "5wvt4CPj4VaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define loss function and optimizer"
      ],
      "metadata": {
        "id": "CdP7pvT84c1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()               # This combines a SoftMax activation and a cross-entropy loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01) # Adam optimizer with learning rate of 0.01"
      ],
      "metadata": {
        "id": "HXKiKuxr4Zyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training loop"
      ],
      "metadata": {
        "id": "_fSKbFPn4iPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')  # Start with a very high initial best loss\n",
        "patience = 10  # Define how many epochs to wait without improvement\n",
        "counter = 0  # Initialize counter\n",
        "\n",
        "for epoch in range(500):   # Increased epochs to ensure convergence with raw data\n",
        "    optimizer.zero_grad()  # Clear out the gradients from the last step\n",
        "    out = model(X_train)   # Forward pass: compute predicted y by passing x to the model\n",
        "    loss = criterion(out, y_train) # Compute the loss\n",
        "    loss.backward()        # Backward pass: compute gradient of the loss with respect to model parameters\n",
        "    optimizer.step()       # Update model parameters\n",
        "\n",
        "    # Evaluate the model's performance on the validation data\n",
        "    # Ensure no gradients are calculated during this step to save computation and memory\n",
        "    with torch.no_grad():\n",
        "        val_out = model(X_test) # Pass the validation data through the model to get predictions.\n",
        "        val_loss = criterion(val_out, y_test) # Compute the validation loss based on the model's predictions and true labels of validation data.\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        counter = 0  # Reset the counter since we have observed an improvement in validation loss.\n",
        "    else:\n",
        "        counter += 1  # If validation loss didn't improve, increment the counter.\n",
        "\n",
        "    # If the number of epochs without improvement exceeds our set patience, stop training.\n",
        "    if counter >= patience:\n",
        "        print(\"Early stopping due to no improvement!\")\n",
        "        break  # Exit the training loop\n",
        "\n",
        "    if (epoch+1) % 50 == 0:  # Print the loss every 50 epochs\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfdz4ZJV4fd6",
        "outputId": "c892c84c-85d5-4da4-c32e-182d14f62e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50, Loss: 0.7173503637313843\n",
            "Epoch 100, Loss: 0.5290992856025696\n",
            "Epoch 150, Loss: 0.4140053987503052\n",
            "Epoch 200, Loss: 0.34220272302627563\n",
            "Epoch 250, Loss: 0.2906952500343323\n",
            "Epoch 300, Loss: 0.2525676190853119\n",
            "Epoch 350, Loss: 0.22402741014957428\n",
            "Epoch 400, Loss: 0.20210480690002441\n",
            "Epoch 450, Loss: 0.18465901911258698\n",
            "Epoch 500, Loss: 0.17038440704345703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the model"
      ],
      "metadata": {
        "id": "ABu40qRv4lNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad(): # Disable gradient computation during evaluation to save memory and speed up the process\n",
        "    test_out = model(X_test)  # Forward pass: compute predicted outputs by passing test data to the model\n",
        "    _, predicted = torch.max(test_out, 1) # Get the class labels with the highest predicted probabilities\n",
        "    accuracy = accuracy_score(y_test.cpu().numpy(), predicted.cpu().numpy()) # Calculate accuracy by comparing predicted and true labels\n",
        "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oj-EKXJc4kKw",
        "outputId": "a9ca830b-3d8f-4c6b-aa17-d88e47fe4894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deployment\n",
        "For deploying a PyTorch model"
      ],
      "metadata": {
        "id": "C8K_BuxV6EFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), \"iris_model.pth\")"
      ],
      "metadata": {
        "id": "GmbkqkR94p0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model for inference\n",
        "model = IrisNet().to(device)\n",
        "model.load_state_dict(torch.load(\"iris_model.pth\"))\n",
        "model.eval()  # Set the model to evaluation mode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUCZMK6N6IKz",
        "outputId": "5fab5ed4-a8f9-42f7-c309-f689ec663718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IrisNet(\n",
              "  (fc1): Linear(in_features=4, out_features=12, bias=True)\n",
              "  (fc2): Linear(in_features=12, out_features=8, bias=True)\n",
              "  (fc3): Linear(in_features=8, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction on new data\n",
        "\n",
        "# Suppose you have new data for prediction as a numpy array\n",
        "new_data = [[5.1, 3.5, 1.4, 0.2],  # Some iris measurements\n",
        "            [6.7, 3.0, 5.2, 2.3]]  # Another set of iris measurements\n",
        "\n",
        "# Convert the data to a PyTorch tensor\n",
        "input_tensor = torch.FloatTensor(new_data)\n",
        "\n",
        "# If you used a GPU during training, move the input tensor to the same device\n",
        "if torch.cuda.is_available():\n",
        "    input_tensor = input_tensor.to('cuda')\n",
        "\n",
        "# Get the model's predictions\n",
        "with torch.no_grad():  # This ensures that the operation is not tracked by PyTorch's autograd\n",
        "    outputs = model(input_tensor)\n",
        "\n",
        "# Get the predicted classes\n",
        "_, predicted_classes = torch.max(outputs, 1)\n",
        "\n",
        "# Convert predicted classes to a list\n",
        "predicted_classes = predicted_classes.tolist()\n",
        "\n",
        "print(predicted_classes)  # This will give you the indices of the predicted classes for each input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7py85k_6M2S",
        "outputId": "a7174685-eb36-47b1-b364-a5e7925c92d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO\n",
        "\n",
        "Next time we will learn about hyperparameters in the context of neural networks.\n",
        "\n",
        "Things we will be looking at:\n",
        "- Learning rate\n",
        "- Batch size\n",
        "- Epochs\n",
        "- Optimizer\n",
        "- Network architecture\n",
        "- Dropout\n",
        "- Regularization\n",
        "- Momentum"
      ],
      "metadata": {
        "id": "xCGZqwd69y1V"
      }
    }
  ]
}